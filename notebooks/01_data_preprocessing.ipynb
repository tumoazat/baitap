{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnam Housing Data Preprocessing\n",
    "\n",
    "This notebook demonstrates the complete data preprocessing pipeline for the Vietnam Housing dataset.\n",
    "\n",
    "## Steps:\n",
    "1. Load and explore raw data\n",
    "2. Remove unnecessary columns\n",
    "3. Handle duplicates\n",
    "4. Handle missing values\n",
    "5. Handle outliers\n",
    "6. Data visualization\n",
    "7. Save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from preprocessing import HousingDataPreprocessor\n",
    "import utils\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data\n",
    "\n",
    "**Note**: Download the dataset from Kaggle:\n",
    "- Dataset: Vietnam Housing Dataset (Hanoi)\n",
    "- Save to: `../data/vietnam_housing.csv`\n",
    "\n",
    "If you don't have the dataset, this notebook will create sample data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = HousingDataPreprocessor()\n",
    "\n",
    "# Try to load data\n",
    "data_path = '../data/vietnam_housing.csv'\n",
    "\n",
    "try:\n",
    "    df = preprocessor.load_data(data_path)\n",
    "    print(\"✓ Real data loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Dataset not found. Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Create sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    sample_data = {\n",
    "        'Unnamed: 0': range(n_samples),\n",
    "        'Ngày': pd.date_range('2023-01-01', periods=n_samples, freq='D'),\n",
    "        'Địa chỉ': [f'Address {i}' for i in range(n_samples)],\n",
    "        'Quận': np.random.choice(['Ba Đình', 'Hoàn Kiếm', 'Đống Đa', 'Hai Bà Trưng', \n",
    "                                  'Cầu Giấy', 'Thanh Xuân', 'Tây Hồ'], n_samples),\n",
    "        'Huyện': np.random.choice(['Ba Đình', 'Hoàn Kiếm', 'Đống Đa', 'Hai Bà Trưng'], n_samples),\n",
    "        'Giá': np.random.uniform(1e9, 20e9, n_samples),\n",
    "        'Diện tích': np.random.uniform(30, 200, n_samples),\n",
    "        'Giá/m²': np.random.uniform(20e6, 150e6, n_samples),\n",
    "        'Số tầng': np.random.randint(1, 6, n_samples),\n",
    "        'Số phòng ngủ': np.random.randint(1, 6, n_samples),\n",
    "        'Dài': np.random.uniform(5, 20, n_samples),\n",
    "        'Rộng': np.random.uniform(3, 15, n_samples),\n",
    "        'Loại hình nhà ở': np.random.choice(['Nhà riêng', 'Nhà mặt phố', 'Biệt thự'], n_samples),\n",
    "        'Giấy tờ pháp lý': np.random.choice(['Sổ đỏ/ Sổ hồng', 'Hợp đồng mua bán'], n_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    # Add some missing values\n",
    "    df.loc[df.sample(50).index, 'Số tầng'] = np.nan\n",
    "    df.loc[df.sample(30).index, 'Loại hình nhà ở'] = np.nan\n",
    "    \n",
    "    preprocessor.df = df\n",
    "    print(f\"✓ Sample data created: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "utils.print_data_info(df, \"Raw Dataset Information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Remove Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.remove_unnecessary_columns()\n",
    "print(f\"Shape after removing columns: {preprocessor.df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.remove_duplicates()\n",
    "print(f\"Shape after removing duplicates: {preprocessor.df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.handle_missing_values()\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "missing_after = preprocessor.df.isnull().sum()\n",
    "print(missing_after[missing_after > 0] if missing_after.any() else \"No missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers before removal\n",
    "if 'Giá' in preprocessor.df.columns:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for idx, col in enumerate(['Giá', 'Diện tích', 'Giá/m²']):\n",
    "        if col in preprocessor.df.columns:\n",
    "            axes[idx].boxplot(preprocessor.df[col].dropna())\n",
    "            axes[idx].set_title(f'{col} - Before Outlier Removal')\n",
    "            axes[idx].set_ylabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "preprocessor.handle_outliers(method='iqr', threshold=1.5)\n",
    "print(f\"Shape after removing outliers: {preprocessor.df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "if 'Giá' in preprocessor.df.columns:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(preprocessor.df['Giá'] / 1e9, bins=50, edgecolor='black')\n",
    "    plt.xlabel('Giá (tỷ VNĐ)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Price Distribution')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(preprocessor.df['Giá'] / 1e9)\n",
    "    plt.ylabel('Giá (tỷ VNĐ)')\n",
    "    plt.title('Price Box Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by district\n",
    "if 'Quận' in preprocessor.df.columns and 'Giá' in preprocessor.df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    district_price = preprocessor.df.groupby('Quận')['Giá'].mean().sort_values(ascending=False) / 1e9\n",
    "    district_price.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Quận')\n",
    "    plt.ylabel('Giá trung bình (tỷ VNĐ)')\n",
    "    plt.title('Average Price by District')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "numerical_cols = preprocessor.df.select_dtypes(include=[np.number]).columns\n",
    "if len(numerical_cols) > 0:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation = preprocessor.df[numerical_cols].corr()\n",
    "    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0, square=True)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data (before encoding)\n",
    "output_path = '../data/processed_housing_data.csv'\n",
    "\n",
    "preprocessor.df_processed = preprocessor.df.copy()\n",
    "preprocessor.save_processed_data(output_path)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {preprocessor.df_processed.shape}\")\n",
    "print(\"\\nData preprocessing completed successfully! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. ✓ Loaded raw housing data\n",
    "2. ✓ Removed unnecessary columns\n",
    "3. ✓ Handled duplicate records\n",
    "4. ✓ Handled missing values according to rules\n",
    "5. ✓ Removed outliers using IQR method\n",
    "6. ✓ Visualized data distributions and relationships\n",
    "7. ✓ Saved processed data for model training\n",
    "\n",
    "**Next Step**: Use `02_model_training.ipynb` to train and evaluate ML models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
