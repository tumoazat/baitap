{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnam Housing Price Prediction - Model Training\n",
    "\n",
    "This notebook demonstrates model training and evaluation for housing price prediction.\n",
    "\n",
    "## Steps:\n",
    "1. Load processed data\n",
    "2. Feature engineering\n",
    "3. Train multiple models\n",
    "4. Model comparison\n",
    "5. Hyperparameter tuning\n",
    "6. Final evaluation\n",
    "7. Save best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from model import HousingPriceModel\n",
    "from preprocessing import HousingDataPreprocessor\n",
    "import utils\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_path = '../data/processed_housing_data.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"✓ Processed data loaded: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Processed data not found. Creating sample data...\")\n",
    "    \n",
    "    # Create sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    sample_data = {\n",
    "        'Quận': np.random.choice(['Ba Đình', 'Hoàn Kiếm', 'Đống Đa', 'Hai Bà Trưng', \n",
    "                                  'Cầu Giấy', 'Thanh Xuân'], n_samples),\n",
    "        'Huyện': np.random.choice(['Ba Đình', 'Hoàn Kiếm', 'Đống Đa'], n_samples),\n",
    "        'Giá': np.random.uniform(2e9, 15e9, n_samples),\n",
    "        'Diện tích': np.random.uniform(40, 150, n_samples),\n",
    "        'Giá/m²': np.random.uniform(30e6, 120e6, n_samples),\n",
    "        'Số tầng': np.random.randint(1, 5, n_samples),\n",
    "        'Số phòng ngủ': np.random.randint(2, 5, n_samples),\n",
    "        'Dài': np.random.uniform(5, 15, n_samples),\n",
    "        'Rộng': np.random.uniform(4, 12, n_samples),\n",
    "        'Loại hình nhà ở': np.random.choice(['Nhà riêng', 'Nhà mặt phố', 'Biệt thự'], n_samples),\n",
    "        'Giấy tờ pháp lý': np.random.choice(['Sổ đỏ/ Sổ hồng', 'Hợp đồng mua bán'], n_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(f\"✓ Sample data created: {df.shape}\")\n",
    "\n",
    "# Display info\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "preprocessor = HousingDataPreprocessor()\n",
    "preprocessor.df = df.copy()\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded = preprocessor.encode_categorical()\n",
    "\n",
    "print(\"\\nEncoded Dataset:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "model_trainer = HousingPriceModel(random_state=42)\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = model_trainer.prepare_data(\n",
    "    df_encoded,\n",
    "    target_col='Giá',\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(\"\\nData Split Summary:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all models\n",
    "models = model_trainer.initialize_models()\n",
    "\n",
    "print(\"\\nInitialized Models:\")\n",
    "for name, model in models.items():\n",
    "    print(f\"  - {name}: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all models\n",
    "results = model_trainer.train_all_models(evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Format for better display\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    utils.print_metrics(metrics, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "model_trainer.plot_results(figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on best models\n",
    "print(\"Performing Cross-Validation...\\n\")\n",
    "\n",
    "cv_results = {}\n",
    "for model_name in ['Random Forest', 'XGBoost', 'LightGBM']:\n",
    "    if model_name in model_trainer.models:\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        cv_result = model_trainer.cross_validate_model(model_name, cv=5)\n",
    "        cv_results[model_name] = cv_result\n",
    "\n",
    "# Display CV results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for model_name, result in cv_results.items():\n",
    "    print(f\"{model_name}: {result['mean_score']:.2f} (+/- {result['std_score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model\n",
    "best_model_name = model_trainer.best_model_name\n",
    "print(f\"Best Model: {best_model_name}\\n\")\n",
    "\n",
    "# Display feature importance\n",
    "importance_df = model_trainer.get_feature_importance(top_n=15)\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "model_trainer.plot_feature_importance(top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Tune Random Forest\n",
    "# Uncomment to run (takes time)\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [15, 20, 25],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [1, 2]\n",
    "# }\n",
    "\n",
    "# best_rf = model_trainer.hyperparameter_tuning(\n",
    "#     'Random Forest',\n",
    "#     param_grid_rf,\n",
    "#     cv=3\n",
    "# )\n",
    "\n",
    "print(\"Hyperparameter tuning skipped (uncomment code to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model_trainer.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test / 1e9, y_pred / 1e9, alpha=0.5)\n",
    "plt.plot([y_test.min() / 1e9, y_test.max() / 1e9], \n",
    "         [y_test.min() / 1e9, y_test.max() / 1e9], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Price (tỷ VNĐ)')\n",
    "plt.ylabel('Predicted Price (tỷ VNĐ)')\n",
    "plt.title(f'Actual vs Predicted - {best_model_name}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = (y_test - y_pred) / 1e9\n",
    "plt.scatter(y_pred / 1e9, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Price (tỷ VNĐ)')\n",
    "plt.ylabel('Residuals (tỷ VNĐ)')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Make Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample input\n",
    "sample_input = utils.create_sample_input(\n",
    "    district='Ba Đình',\n",
    "    property_type='Nhà riêng',\n",
    "    area=100.0,\n",
    "    floors=3,\n",
    "    bedrooms=3,\n",
    "    length=10.0,\n",
    "    width=10.0\n",
    ")\n",
    "\n",
    "print(\"Sample Input:\")\n",
    "for key, value in sample_input.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Note: For actual prediction, we need to encode the input\n",
    "print(\"\\n⚠️ To make actual predictions, the input needs to be encoded using the same\")\n",
    "print(\"encoders used during training. See the Streamlit app for full implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = '../models/best_housing_model.pkl'\n",
    "\n",
    "model_trainer.save_model(filepath=model_path)\n",
    "\n",
    "print(f\"\\n✓ Best model ({best_model_name}) saved successfully!\")\n",
    "print(f\"Model path: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Test Loading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model trainer and load the saved model\n",
    "test_trainer = HousingPriceModel()\n",
    "loaded_model = test_trainer.load_model(model_path)\n",
    "\n",
    "# Make a test prediction\n",
    "test_pred = test_trainer.predict(X_test[:5])\n",
    "\n",
    "print(\"\\nTest Predictions (first 5):\")\n",
    "for i, (actual, predicted) in enumerate(zip(y_test[:5], test_pred)):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Actual:    {actual/1e9:.2f} tỷ VNĐ\")\n",
    "    print(f\"  Predicted: {predicted/1e9:.2f} tỷ VNĐ\")\n",
    "    print(f\"  Error:     {abs(actual - predicted)/1e9:.2f} tỷ VNĐ\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. ✓ Loaded processed data\n",
    "2. ✓ Performed feature engineering\n",
    "3. ✓ Trained 4 different ML models\n",
    "4. ✓ Compared model performance\n",
    "5. ✓ Performed cross-validation\n",
    "6. ✓ Analyzed feature importance\n",
    "7. ✓ Saved the best model\n",
    "\n",
    "**Best Model**: {best_model_name}\n",
    "\n",
    "**Next Step**: Use the Streamlit app (`streamlit run app/streamlit_app.py`) for interactive predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
